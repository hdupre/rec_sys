{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "#### Harris Dupre\n",
    "#### Data 612, Summer 2020\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This final project will be a hybrid book recommender system implemented in Python using the goodbooks data found here:\n",
    "\n",
    "https://www.kaggle.com/zygmunt/goodbooks-10k\n",
    "\n",
    "The goodbooks dataset contains six million total ratings, with ten thousand books and fifty thousand users. However, this size set was prohibitively large, so the set I used has just over one million ratings.\n",
    "\n",
    "My intention was to use the sci-kit Surprise library to generate prediction matrices, processing time, and RMSE data on a number of different recommender algorithms and compare the results. My ultimate goal was to create a hybridized recommender system that would aggregate the user-item rating predictions and assign varying weights based on prediction algorithm that generated a particular value.\n",
    "\n",
    "This did not go as planned (as I will discuss in the sci-kit Surprise section below). Instead I generated an SVD prediction matrix to using the numpy linear algebra library to start my recommendation list, then used a \"nearest neighbors\" function to find similar books that the user might be interested in.\n",
    "\n",
    "\n",
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "from surprise import Reader, Dataset, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, SlopeOne, BaselineOnly, NormalPredictor\n",
    "\n",
    "r = pd.read_csv('ratings.csv')\n",
    "r = r[r['user_id'].isin(r['user_id'].value_counts().head(7000).index.tolist())]\n",
    "\n",
    "tr = pd.read_csv('to_read.csv')\n",
    "b = pd.read_csv('books.csv')\n",
    "t = pd.read_csv('tags.csv')\n",
    "\n",
    "bt = pd.read_csv('book_tags.csv')\n",
    "bt = bt.merge( t, on = 'tag_id' )\n",
    "bt = bt.merge( b[[ 'goodreads_book_id', 'title']], on = 'goodreads_book_id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings DataFrame\n",
    "\n",
    "The ratings dataframe, read from 'ratings.csv' will be the core of the recommender system as its user-item combinations, and the corresponding ratings, will be used to train prediction models.\n",
    "\n",
    "Note that while loading the data I selected the top 7000 users who had the most books rated. This change saved me about five million records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>75</td>\n",
       "      <td>3254</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>75</td>\n",
       "      <td>6777</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>75</td>\n",
       "      <td>372</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>75</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>75</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  book_id  rating\n",
       "977       75     3254       2\n",
       "978       75     6777       5\n",
       "979       75       11       5\n",
       "981       75      372       4\n",
       "982       75      476       3\n",
       "983       75      115       4"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD1CAYAAAClSgmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWvklEQVR4nO3df6zd9X3f8ecrdqCsWcDADWO2U6PGW+NkixNuwVOmKYXMGIhqIoFqNAUr8uYuMmqqVF1M9wdtEiTyR8uKlLDR4GKiLo5HG+ElTj0PyKpqCfiSuBBDI26JFxwTuMSGkNGADO/9cT6uD5fzvff4B+d69fMhHZ3v9/39fD7fzzlwz8vfH+feVBWSJA3yprmegCTp5GVISJI6GRKSpE6GhCSpkyEhSepkSEiSOs0ftmGSecAE8MOq+lCSC4AtwNnAt4GPVNXLSU4H7gIuBH4M/FpV7W1j3ACsA14BfqOqdrT6KuAPgXnAF6rq5lYfuI+Z5nnuuefWkiVLhn1ZkiTgoYceeraqxqbXhw4J4OPAY8Bb2/pngVuqakuS/0zvw/+29nywqt6RZE1r92tJlgFrgHcB/xj4n0n+SRvrc8C/BvYBu5Jsq6pHZ9hHpyVLljAxMXEUL0uSlOT/DKoPdbopySLgSuALbT3AJcDdrclm4Kq2vLqt07Zf2tqvBrZU1UtV9X1gErioPSar6ol2lLAFWD3LPiRJIzDsNYn/BPwH4NW2fg7wXFUdauv7gIVteSHwJEDb/nxr/3f1aX266jPtQ5I0ArOGRJIPAc9U1UP95QFNa5ZtJ6o+aI7rk0wkmZiamhrURJJ0DIY5kng/8KtJ9tI7FXQJvSOLs5IcvqaxCNjflvcBiwHa9jOBA/31aX266s/OsI/XqKrbq2q8qsbHxl533UWSdIxmDYmquqGqFlXVEnoXnu+rqn8D3A9c3ZqtBe5py9vaOm37fdX7LYLbgDVJTm93LS0FHgR2AUuTXJDktLaPba1P1z4kSSNwPN+T+CTwiSST9K4f3NHqdwDntPongI0AVbUH2Ao8Cvw5sKGqXmnXHK4HdtC7e2prazvTPiRJI5C/b78qfHx8vLwFVpKOTpKHqmp8et1vXEuSOh3Nl+l0Clqy8WtzPQX23nzlXE9BOmV5JCFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6GhCSp06whkeTnkjyY5K+S7Enye61+Z5LvJ9ndHstbPUluTTKZ5OEk7+sba22Sx9tjbV/9wiSPtD63Jkmrn51kZ2u/M8mCE/8WSJK6DHMk8RJwSVW9B1gOrEqyom377apa3h67W+1yYGl7rAdug94HPnAjcDFwEXBj34f+ba3t4X6rWn0jcG9VLQXubeuSpBGZNSSq56dt9c3tUTN0WQ3c1fp9CzgryfnAZcDOqjpQVQeBnfQC53zgrVX1zaoq4C7gqr6xNrflzX11SdIIDHVNIsm8JLuBZ+h90D/QNt3UTindkuT0VlsIPNnXfV+rzVTfN6AOcF5VPQXQnt/WMb/1SSaSTExNTQ3zkiRJQxgqJKrqlapaDiwCLkrybuAG4JeAXwbOBj7ZmmfQEMdQH1pV3V5V41U1PjY2djRdJUkzOKq7m6rqOeAbwKqqeqqdUnoJ+GN61xmgdySwuK/bImD/LPVFA+oAT7fTUbTnZ45mvpKk4zPM3U1jSc5qy2cAHwT+uu/DO/SuFXy3ddkGXNfucloBPN9OFe0AViZZ0C5YrwR2tG0vJFnRxroOuKdvrMN3Qa3tq0uSRmD+EG3OBzYnmUcvVLZW1VeT3JdkjN7pot3Av2/ttwNXAJPAi8BHAarqQJJPA7tau09V1YG2/DHgTuAM4OvtAXAzsDXJOuAHwDXH+kIlSUdv1pCoqoeB9w6oX9LRvoANHds2AZsG1CeAdw+o/xi4dLY5SpLeGH7jWpLUyZCQJHUa5prEKWfJxq/N9RTYe/OVcz0FSfJIQpLUzZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnWYNiSQ/l+TBJH+VZE+S32v1C5I8kOTxJF9Oclqrn97WJ9v2JX1j3dDq30tyWV99VatNJtnYVx+4D0nSaAxzJPEScElVvQdYDqxKsgL4LHBLVS0FDgLrWvt1wMGqegdwS2tHkmXAGuBdwCrg80nmJZkHfA64HFgGXNvaMsM+JEkjMGtIVM9P2+qb26OAS4C7W30zcFVbXt3WadsvTZJW31JVL1XV94FJ4KL2mKyqJ6rqZWALsLr16dqHJGkEhrom0f7Fvxt4BtgJ/A3wXFUdak32AQvb8kLgSYC2/XngnP76tD5d9XNm2Mf0+a1PMpFkYmpqapiXJEkawlAhUVWvVNVyYBG9f/m/c1Cz9pyObSeqPmh+t1fVeFWNj42NDWoiSToGR3V3U1U9B3wDWAGclWR+27QI2N+W9wGLAdr2M4ED/fVpfbrqz86wD0nSCAxzd9NYkrPa8hnAB4HHgPuBq1uztcA9bXlbW6dtv6+qqtXXtLufLgCWAg8Cu4Cl7U6m0+hd3N7W+nTtQ5I0AvNnb8L5wOZ2F9KbgK1V9dUkjwJbknwG+A5wR2t/B/DFJJP0jiDWAFTVniRbgUeBQ8CGqnoFIMn1wA5gHrCpqva0sT7ZsQ9J0gjMGhJV9TDw3gH1J+hdn5he/xlwTcdYNwE3DahvB7YPuw9J0mj4jWtJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktRpmN/dJAlYsvFrcz0F9t585VxPQacYjyQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUqdh/sb14iT3J3ksyZ4kH2/1303ywyS72+OKvj43JJlM8r0kl/XVV7XaZJKNffULkjyQ5PEkX25/65r297C/3No/kGTJiXzxkqSZDXMkcQj4rap6J7AC2JBkWdt2S1Utb4/tAG3bGuBdwCrg80nmtb+R/TngcmAZcG3fOJ9tYy0FDgLrWn0dcLCq3gHc0tpJkkZk1pCoqqeq6ttt+QXgMWDhDF1WA1uq6qWq+j4wSe/vVF8ETFbVE1X1MrAFWJ0kwCXA3a3/ZuCqvrE2t+W7gUtbe0nSCBzVNYl2uue9wAOtdH2Sh5NsSrKg1RYCT/Z129dqXfVzgOeq6tC0+mvGatufb+0lSSMwdEgkeQvwp8BvVtVPgNuAXwSWA08Bv3+46YDudQz1mcaaPrf1SSaSTExNTc34OiRJwxsqJJK8mV5A/ElV/RlAVT1dVa9U1avAH9E7nQS9I4HFfd0XAftnqD8LnJVk/rT6a8Zq288EDkyfX1XdXlXjVTU+NjY2zEuSJA1hmLubAtwBPFZVf9BXP7+v2YeB77blbcCadmfSBcBS4EFgF7C03cl0Gr2L29uqqoD7gatb/7XAPX1jrW3LVwP3tfaSpBEY5rfAvh/4CPBIkt2t9jv07k5aTu/0z17g1wGqak+SrcCj9O6M2lBVrwAkuR7YAcwDNlXVnjbeJ4EtST4DfIdeKNGev5hkkt4RxJrjeK2SpKM0a0hU1V8y+NrA9hn63ATcNKC+fVC/qnqCI6er+us/A66ZbY6SpDeG37iWJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ1mDYkki5Pcn+SxJHuSfLzVz06yM8nj7XlBqyfJrUkmkzyc5H19Y61t7R9PsravfmGSR1qfW5Nkpn1IkkZjmCOJQ8BvVdU7gRXAhiTLgI3AvVW1FLi3rQNcDixtj/XAbdD7wAduBC6m9/esb+z70L+ttT3cb1Wrd+1DkjQCs4ZEVT1VVd9uyy8AjwELgdXA5tZsM3BVW14N3FU93wLOSnI+cBmws6oOVNVBYCewqm17a1V9s6oKuGvaWIP2IUkagaO6JpFkCfBe4AHgvKp6CnpBArytNVsIPNnXbV+rzVTfN6DODPuQJI3A0CGR5C3AnwK/WVU/manpgFodQ31oSdYnmUgyMTU1dTRdJUkzGCokkryZXkD8SVX9WSs/3U4V0Z6fafV9wOK+7ouA/bPUFw2oz7SP16iq26tqvKrGx8bGhnlJkqQhDHN3U4A7gMeq6g/6Nm0DDt+htBa4p69+XbvLaQXwfDtVtANYmWRBu2C9EtjRtr2QZEXb13XTxhq0D0nSCMwfos37gY8AjyTZ3Wq/A9wMbE2yDvgBcE3bth24ApgEXgQ+ClBVB5J8GtjV2n2qqg605Y8BdwJnAF9vD2bYhyRpBGYNiar6SwZfNwC4dED7AjZ0jLUJ2DSgPgG8e0D9x4P2IUkaDb9xLUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6zRoSSTYleSbJd/tqv5vkh0l2t8cVfdtuSDKZ5HtJLuurr2q1ySQb++oXJHkgyeNJvpzktFY/va1Ptu1LTtSLliQNZ5gjiTuBVQPqt1TV8vbYDpBkGbAGeFfr8/kk85LMAz4HXA4sA65tbQE+28ZaChwE1rX6OuBgVb0DuKW1kySN0KwhUVV/ARwYcrzVwJaqeqmqvg9MAhe1x2RVPVFVLwNbgNVJAlwC3N36bwau6htrc1u+G7i0tZckjcjxXJO4PsnD7XTUglZbCDzZ12Zfq3XVzwGeq6pD0+qvGattf761f50k65NMJJmYmpo6jpckSep3rCFxG/CLwHLgKeD3W33Qv/TrGOozjfX6YtXtVTVeVeNjY2MzzVuSdBSOKSSq6umqeqWqXgX+iN7pJOgdCSzua7oI2D9D/VngrCTzp9VfM1bbfibDn/aSJJ0AxxQSSc7vW/0wcPjOp23AmnZn0gXAUuBBYBewtN3JdBq9i9vbqqqA+4GrW/+1wD19Y61ty1cD97X2kqQRmT9bgyRfAj4AnJtkH3Aj8IEky+md/tkL/DpAVe1JshV4FDgEbKiqV9o41wM7gHnApqra03bxSWBLks8A3wHuaPU7gC8mmaR3BLHmuF+tJOmozBoSVXXtgPIdA2qH298E3DSgvh3YPqD+BEdOV/XXfwZcM9v8JElvHL9xLUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6zRoSSTYleSbJd/tqZyfZmeTx9ryg1ZPk1iSTSR5O8r6+Pmtb+8eTrO2rX5jkkdbn1iSZaR+SpNEZ5kjiTmDVtNpG4N6qWgrc29YBLgeWtsd64DbofeADNwIX0/t71jf2fejf1toe7rdqln1IkkZk1pCoqr8ADkwrrwY2t+XNwFV99buq51vAWUnOBy4DdlbVgao6COwEVrVtb62qb1ZVAXdNG2vQPiRJI3Ks1yTOq6qnANrz21p9IfBkX7t9rTZTfd+A+kz7eJ0k65NMJJmYmpo6xpckSZruRF+4zoBaHUP9qFTV7VU1XlXjY2NjR9tdktThWEPi6XaqiPb8TKvvAxb3tVsE7J+lvmhAfaZ9SJJG5FhDYhtw+A6ltcA9ffXr2l1OK4Dn26miHcDKJAvaBeuVwI627YUkK9pdTddNG2vQPiRJIzJ/tgZJvgR8ADg3yT56dyndDGxNsg74AXBNa74duAKYBF4EPgpQVQeSfBrY1dp9qqoOXwz/GL07qM4Avt4ezLAPSdKIzBoSVXVtx6ZLB7QtYEPHOJuATQPqE8C7B9R/PGgfkqTR8RvXkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6zfuNakqZbsvFrcz0F9t585VxP4ZTgkYQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6HVdIJNmb5JEku5NMtNrZSXYmebw9L2j1JLk1yWSSh5O8r2+cta3940nW9tUvbONPtr45nvlKko7OiTiS+JWqWl5V4219I3BvVS0F7m3rAJcDS9tjPXAb9EKF3t/Nvhi4CLjxcLC0Nuv7+q06AfOVJA3pjTjdtBrY3JY3A1f11e+qnm8BZyU5H7gM2FlVB6rqILATWNW2vbWqvtn+dvZdfWNJkkbgeEOigP+R5KEk61vtvKp6CqA9v63VFwJP9vXd12oz1fcNqEuSRuR4f3fT+6tqf5K3ATuT/PUMbQddT6hjqL9+4F5ArQd4+9vfPvOMJUlDO64jiara356fAb5C75rC0+1UEe35mdZ8H7C4r/siYP8s9UUD6oPmcXtVjVfV+NjY2PG8JElSn2MOiSQ/n+QfHl4GVgLfBbYBh+9QWgvc05a3Ade1u5xWAM+301E7gJVJFrQL1iuBHW3bC0lWtLuarusbS5I0Asdzuuk84CvtrtT5wH+tqj9PsgvYmmQd8APgmtZ+O3AFMAm8CHwUoKoOJPk0sKu1+1RVHWjLHwPuBM4Avt4ekqQROeaQqKongPcMqP8YuHRAvYANHWNtAjYNqE8A7z7WOUqSjo/fuJYkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1Ol4f8GfJJ3Slmz82lxPgb03X/mGje2RhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKnTSR8SSVYl+V6SySQb53o+knQqOalDIsk84HPA5cAy4Noky+Z2VpJ06jipQwK4CJisqieq6mVgC7B6juckSaeMVNVcz6FTkquBVVX1b9v6R4CLq+r6ae3WA+vb6j8FvjfSib7eucCzczyHk4XvxRG+F0f4XhxxsrwXv1BVY9OLJ/tvgc2A2utSrapuB25/46cznCQTVTU+1/M4GfheHOF7cYTvxREn+3txsp9u2gcs7ltfBOyfo7lI0innZA+JXcDSJBckOQ1YA2yb4zlJ0injpD7dVFWHklwP7ADmAZuqas8cT2sYJ82pr5OA78URvhdH+F4ccVK/Fyf1hWtJ0tw62U83SZLmkCEhSepkSEiSOhkSJ1iSf5nkE0lWzvVcTgZJ7prrOcyVJBcl+eW2vKz9f3HFXM9rLiT5pSSXJnnLtPqquZqThuOF6+OU5MGquqgt/ztgA/AVYCXw36vq5rmc3yglmX57coBfAe4DqKpfHfmk5kiSG+n9zrH5wE7gYuAbwAeBHVV109zNbrSS/Aa9n4vHgOXAx6vqnrbt21X1vrmc38kiyUer6o/neh7TGRLHKcl3quq9bXkXcEVVTSX5eeBbVfXP5naGo5Pk28CjwBfofTM+wJfofb+Fqvpfcze70UryCL0PxNOBHwGLquonSc4AHqiqfz6nExyh9l78i6r6aZIlwN3AF6vqD/t/fk51SX5QVW+f63lMd1J/T+L/E29KsoDeqbtU1RRAVf3fJIfmdmojNw58HPiPwG9X1e4kf3sqhUOfQ1X1CvBikr+pqp8AVNXfJnl1juc2avOq6qcAVbU3yQeAu5P8AoN/9c7fW0ke7toEnDfKuQzLkDh+ZwIP0fuPXEn+UVX9qJ17PaV+AKrqVeCWJP+tPT/Nqfv/2MtJ/kFVvQhceLiY5EzgVAuJHyVZXlW7AdoRxYeATcApc6TdnAdcBhycVg/wv0c/ndmdqj/AJ0xVLenY9Crw4RFO5aRRVfuAa5JcCfxkruczR/5VVb0Efxeeh70ZWDs3U5oz1wGvOaquqkPAdUn+y9xMac58FXjL4cDsl+Qbo5/O7LwmIUnq5C2wkqROhoQkqZMhIUnqZEhIkjoZEpKkTv8PVBWvqljYlHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r['rating'].value_counts().loc[[5,4,3,2,1]].plot(kind='bar', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that that the most common rating is 4, with the vast majority of ratings being 3 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book DataFrame\n",
    "\n",
    "This dataframe also plays an important role as it stores data about each book item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "2        3              41865         41865  3212258          226  316015849   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Book file\n",
    "b.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sci-Kit Surprise as a Recommender Tool\n",
    "\n",
    "As I stated earlier, my intention was to use the Surprise library to generate all my prediction data, and then use that data to create a hybridized recommender system.\n",
    "\n",
    "I used this library with good success on Project 4, and it allowed me to compare SVD, user-based collaborative filtering, and item-based collaborative filtering -- but the dataset was much smaller.\n",
    "\n",
    "Surprise worked decently well on this dataset with certain algorithms while only generating a prediction matrix for a portion of the data.\n",
    "\n",
    "Collaborative filtering algorithms and prediction matrices for the whole set were not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reader that takes the rating scale as a parameter\n",
    "# use the load_from_df function to load our book ratings dataframe\n",
    "# split data into a training set and a test set with an 80/20 ratio\n",
    "trainset, testset = train_test_split(Dataset.load_from_df(r[['user_id', 'book_id','rating']], Reader(rating_scale=(1,5))), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise recommender algorithm functions\n",
    "algo_svd = SVD()\n",
    "algo_so = SlopeOne()\n",
    "algo_bslo = BaselineOnly()\n",
    "algo_np = NormalPredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tic = timeit.default_timer()\n",
    "algo_svd.fit(trainset)\n",
    "toc = timeit.default_timer()\n",
    "time_a = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "algo_so.fit(trainset)\n",
    "toc = timeit.default_timer()\n",
    "time_b = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "tic = timeit.default_timer()\n",
    "algo_bslo.fit(trainset)\n",
    "toc = timeit.default_timer()\n",
    "time_c = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "algo_np.fit(trainset)\n",
    "toc = timeit.default_timer()\n",
    "time_d = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "pred_svd = algo_svd.test(testset)\n",
    "toc = timeit.default_timer()\n",
    "time1 = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "pred_so = algo_so.test(testset)\n",
    "toc = timeit.default_timer()\n",
    "time2 = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "pred_bslo = algo_bslo.test(testset)\n",
    "toc = timeit.default_timer()\n",
    "time3 = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timeit.default_timer()\n",
    "pred_np = algo_np.test(testset)\n",
    "toc = timeit.default_timer()\n",
    "time4 = round(toc-tic,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8415\n",
      "RMSE: 0.8519\n",
      "RMSE: 0.8553\n",
      "RMSE: 1.3386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Prediction Values Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>46.6264</td>\n",
       "      <td>2.2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SlopeOne</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>13.0015</td>\n",
       "      <td>26.6556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaselineOnly</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>2.2488</td>\n",
       "      <td>1.3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NormalPredictor</td>\n",
       "      <td>1.3386</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>1.9912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm    RMSE  Training Time  Prediction Values Time\n",
       "0              SVD  0.8415        46.6264                  2.2481\n",
       "1         SlopeOne  0.8519        13.0015                 26.6556\n",
       "2     BaselineOnly  0.8553         2.2488                  1.3278\n",
       "3  NormalPredictor  1.3386         0.9158                  1.9912"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['SVD',accuracy.rmse(pred_svd).round(4),time_a,time1],['SlopeOne',accuracy.rmse(pred_so).round(4),time_b,time2],['BaselineOnly',accuracy.rmse(pred_bslo).round(4),time_c,time3],['NormalPredictor',accuracy.rmse(pred_np).round(4),time_d,time4]],columns=['Algorithm','RMSE','Training Time','Prediction Values Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVDs training time was the longest, but compared to generating the overall prediction matrix for SVD (which took 3-4 hours) it was nothing.\n",
    "\n",
    "SVD had the lowest RMSE while the NormalPredictor had the highest, as was expected for both.\n",
    "\n",
    "The commented out functions below could not be run on my hardware, they took hours to run and I never successfully ran all three without the kernel failing. Kernel failure is particularly rough if you've already generated data from a long-running process and you have to start all over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_svd_full = algo_svd.test(trainset.build_anti_testset())\n",
    "# pred_so_full = algo_so.test(trainset.build_anti_testset())\n",
    "# pred_bslo_full = algo_bslo.test(trainset.build_anti_testset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing SVD a different way\n",
    "\n",
    "Because I was unable to generate predictions for all my data using Surprise, I turned to using the svd functions of the numpy.linalg library. This had worked well for me in Project 3 and I was hoping that performance would be better using numpy and pandas to do matrix calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of user-item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mat = r.pivot_table(index='user_id', columns='book_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id  1      2      3      4      5      6      7      8      9      10     \\\n",
       "user_id                                                                         \n",
       "7          NaN    NaN    NaN    NaN    3.0    NaN    NaN    2.0    NaN    NaN   \n",
       "35         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "41         5.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "75         4.0    5.0    NaN    NaN    NaN    4.0    NaN    4.0    NaN    2.0   \n",
       "89         4.0    3.0    NaN    4.0    4.0    NaN    4.0    4.0    NaN    3.0   \n",
       "\n",
       "book_id  ...  9991   9992   9993   9994   9995   9996   9997   9998   9999   \\\n",
       "user_id  ...                                                                  \n",
       "7        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "35       ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "41       ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "75       ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "89       ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "book_id  10000  \n",
       "user_id         \n",
       "7          NaN  \n",
       "35         NaN  \n",
       "41         NaN  \n",
       "75         NaN  \n",
       "89         NaN  \n",
       "\n",
       "[5 rows x 9888 columns]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numpy.linalg.svd() to generate a prediction matrix for all the data\n",
    "\n",
    "Note that I replaced all the NaN with 0 when I passed r_mat to svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time:  179.3497  seconds.\n"
     ]
    }
   ],
   "source": [
    "tic = timeit.default_timer()\n",
    "u, s, v_t = np.linalg.svd(r_mat.replace(np.nan, 0), full_matrices=False)\n",
    "toc = timeit.default_timer()\n",
    "print('Processing time: ', round(toc-tic,4),' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a short processing time but far better than Surprise's hours of processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 7000) (7000,) (7000, 9888)\n"
     ]
    }
   ],
   "source": [
    "print(u.shape,s.shape,v_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time:  14.0039  seconds.\n"
     ]
    }
   ],
   "source": [
    "tic = timeit.default_timer()\n",
    "svd_prediction_df = pd.DataFrame(np.dot(u, np.dot(np.diag(s),v_t)), columns= r_mat.columns, index=r_mat.index)\n",
    "toc = timeit.default_timer()\n",
    "print('Processing time: ', round(toc-tic,4),' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing recommender_svd() to retrieve top user predictions.\n",
    "\n",
    "This function is adapted from one I wrote for the Movie Lens dataset in Project 3.\n",
    "\n",
    "The function finds the highest user-item combination values for given user, and outputs a list of book titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_svd(user_id, svd_prediction_df,b):\n",
    "    # column of the selected user's predicted ratings\n",
    "    user = svd_prediction_df.loc[user_id, :].sort_values(ascending=False)\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    list_svd = []\n",
    "    \n",
    "    while i < 20:\n",
    "        # if the user rating is NaN in the ratings pivot, the user didn't rate the selected book so it \n",
    "        # can be recommended. Otherwise, skip.\n",
    "        if (np.isnan(r_mat.at[user_id,user.index[j]])):\n",
    "            title = b[b['book_id']==user.index[j]]['original_title'].to_string(index=False).strip()\n",
    "            list_svd.append(title)\n",
    "            \n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n",
    "        \n",
    "    return pd.DataFrame(list_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender_knn() to diversify predictions a bit\n",
    "\n",
    "I adapted this function from a function I wrote for Project 2 which dealt with the Jokes data.\n",
    "\n",
    "The function takes a user matrix with user_id as the columns and book_id as the index.\n",
    "\n",
    "Again I replace NaN with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_user = r.pivot(index='book_id', columns='user_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>7</th>\n",
       "      <th>35</th>\n",
       "      <th>41</th>\n",
       "      <th>75</th>\n",
       "      <th>89</th>\n",
       "      <th>143</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>153</th>\n",
       "      <th>158</th>\n",
       "      <th>...</th>\n",
       "      <th>53293</th>\n",
       "      <th>53318</th>\n",
       "      <th>53332</th>\n",
       "      <th>53337</th>\n",
       "      <th>53352</th>\n",
       "      <th>53364</th>\n",
       "      <th>53366</th>\n",
       "      <th>53373</th>\n",
       "      <th>53381</th>\n",
       "      <th>53403</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 7000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id  7      35     41     75     89     143    145    146    153    158    \\\n",
       "book_id                                                                         \n",
       "1          0.0    0.0    5.0    4.0    4.0    5.0    0.0    0.0    0.0    0.0   \n",
       "2          0.0    0.0    0.0    5.0    3.0    5.0    0.0    0.0    0.0    0.0   \n",
       "3          0.0    0.0    0.0    0.0    0.0    3.0    2.0    0.0    0.0    0.0   \n",
       "4          0.0    0.0    0.0    0.0    4.0    0.0    3.0    5.0    0.0    4.0   \n",
       "5          3.0    0.0    0.0    0.0    4.0    0.0    0.0    0.0    0.0    0.0   \n",
       "6          0.0    0.0    0.0    4.0    0.0    3.0    0.0    0.0    4.0    0.0   \n",
       "\n",
       "user_id  ...  53293  53318  53332  53337  53352  53364  53366  53373  53381  \\\n",
       "book_id  ...                                                                  \n",
       "1        ...    0.0    4.0    5.0    4.0    5.0    0.0    4.0    5.0    5.0   \n",
       "2        ...    0.0    0.0    0.0    5.0    5.0    0.0    4.0    5.0    5.0   \n",
       "3        ...    0.0    2.0    1.0    4.0    0.0    0.0    5.0    3.0    4.0   \n",
       "4        ...    0.0    0.0    5.0    5.0    1.0    4.0    3.0    4.0    5.0   \n",
       "5        ...    0.0    0.0    4.0    4.0    0.0    0.0    3.0    2.0    5.0   \n",
       "6        ...    0.0    4.0    5.0    0.0    0.0    0.0    5.0    0.0    4.0   \n",
       "\n",
       "user_id  53403  \n",
       "book_id         \n",
       "1          0.0  \n",
       "2          4.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "5          0.0  \n",
       "6          0.0  \n",
       "\n",
       "[6 rows x 7000 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_user.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mat = csr_matrix(r_user.values)\n",
    "knn = NearestNeighbors(metric='cosine', algorithm = 'brute', n_neighbors=20)\n",
    "knn.fit(user_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_knn(book_id, user_mat):\n",
    "    book_id -= 1\n",
    "    list_knn = []\n",
    "    \n",
    "    distances, indices = knn.kneighbors(user_mat[book_id], n_neighbors=5)\n",
    "    \n",
    "    for i in range(5):\n",
    "        list_knn.append(b['original_title'][indices[0][i]])\n",
    "        \n",
    "    return pd.DataFrame(list_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get_nearest\n",
    "\n",
    "The idea here is the get the top 20 book recommendations from the SVD prediction matrix, then find the five nearest neighbors each of those top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest(fav_ids):\n",
    "    frames = []\n",
    "    for i in range(len(fav_ids)):\n",
    "        frames.append((recommender_knn(fav_ids[i], user_mat)))\n",
    "    df=pd.concat(frames,sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hobbit or There and Back Again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fellowship of the Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nineteen Eighty-Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lion, the Witch and the Wardrobe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0\n",
       "0        The Hobbit or There and Back Again\n",
       "1                The Fellowship of the Ring\n",
       "2  Harry Potter and the Philosopher's Stone\n",
       "3                      Nineteen Eighty-Four\n",
       "4      The Lion, the Witch and the Wardrobe"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nearest([7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The recs function\n",
    "\n",
    "The recs() function puts it together by generating a top 20 dataframe of books for a user, finding the nearest neighbors of those 20 books and putting them in a dataframe, and then selecting from both of those dataframe to develop a final recommendation list.\n",
    "\n",
    "The first five results of the final list are the top 5 SVD predictions, while the other five are the most commonly recommended neighbors of the SVD predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recs(user_id):\n",
    "    \n",
    "    # get svd recommendations\n",
    "    df_svd = recommender_svd(user_id, svd_prediction_df,b)\n",
    "    \n",
    "    # get the ids of the svd recommendations\n",
    "    fav_ids = b[b['original_title'].isin(df_svd[0])]['book_id'].reset_index(drop=True)\n",
    "    \n",
    "    # calculate nearest neighbors to the fav_ids\n",
    "    nearest_df = pd.DataFrame(get_nearest(fav_ids)[0].value_counts().index)\n",
    "    nearest_df = nearest_df[~nearest_df[0].isin(df_svd[0])][0:5]\n",
    "    \n",
    "    # output a list that is half SVD, half nearest neighbors.\n",
    "    print(\"Your recommendations are: \")\n",
    "    return pd.concat([df_svd[0][0:5],nearest_df[0][0:5]]).reset_index(drop=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your recommendations are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    The Adventures of Huckleberry Finn\n",
       "1                Much Ado About Nothing\n",
       "2                   Death of a Salesman\n",
       "3                  The Call of the Wild\n",
       "4     Charlie and the Chocolate Factory\n",
       "5          The Adventures of Tom Sawyer\n",
       "6                      Of Mice and Men \n",
       "7                   The Glass Menagerie\n",
       "8             A Midsummer Night's Dream\n",
       "9                       Charlotte's Web\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "American Classics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your recommendations are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        Nineteen Eighty-Four\n",
       "1                            The Great Gatsby\n",
       "2    Harry Potter and the Philosopher's Stone\n",
       "3         Harry Potter and the Goblet of Fire\n",
       "4        Harry Potter and the Deathly Hallows\n",
       "5                             Charlotte's Web\n",
       "6                       The Lord of the Rings\n",
       "7                                   The Giver\n",
       "8          The Hobbit or There and Back Again\n",
       "9                          Lord of the Flies \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your recommendations are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                      The Catcher in the Rye\n",
       "1                             Angels & Demons\n",
       "2                             The Kite Runner\n",
       "3    Harry Potter and the Prisoner of Azkaban\n",
       "4                                   Gone Girl\n",
       "5                       To Kill a Mockingbird\n",
       "6                            The Kite Runner \n",
       "7         Harry Potter and the Goblet of Fire\n",
       "8      Harry Potter and the Half-Blood Prince\n",
       "9                            The Great Gatsby\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs(153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thrillers and fantasy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Areas of Improvement\n",
    "\n",
    "It appears to me that the final predictions heavily favor American literary classics and some fantasy books. It's possible that subsetting the way I did (almost all users here have rated almost 200+ books) introduced some bias.\n",
    "\n",
    "With more time and processing power I would like to use the Surprise algorithms to generate the prediction matrices -- I think their uniform formats would make them easy to work with.\n",
    "\n",
    "In hindsight I went into this project with too many unknowns. Without knowing exactly what datatypes/data structures these functions would give me it was difficult to accurately gauge how much work it would be to transform the data into useable predictions, and then try hybridize those predictions in a meaningful way.\n",
    "\n",
    "The code itself needs some input control functions. Right now the rec() function will fail if it is given a user_id that does not exist. Instead it should warn the user on input and ask for a valid input.\n",
    "\n",
    "I would have liked to use the code I wrote below for word analysis of the tags that are attached to each book record.\n",
    "\n",
    "My idea was to have some kind of genre filtering and more recommendations based on books that have similar tags to the favorites -- but time was limited.\n",
    "\n",
    "However, I did notice as I was working on this I was more easily navigating panda's dataframes and extracting the data I needed, and I was writing while using fewer variables behind taking up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df=0,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tf.fit_transform(t['tag_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix) \n",
    "results = {}\n",
    "for idx, row in t.iterrows():\n",
    "   similar_indices = cosine_similarities[idx].argsort()[:-100:-1] \n",
    "   similar_items = [(cosine_similarities[idx][i], t['tag_name'][i]) for i in similar_indices] \n",
    "   results[row['tag_name']] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999999, '2-non-fiction')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['non-fiction'][:10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999999999999999, 'non-fiction-etc'),\n",
       " (0.9999999999999999, '2-non-fiction'),\n",
       " (0.9999999999999999, 'non-fiction-other'),\n",
       " (0.9999999999999999, 'all-non-fiction'),\n",
       " (0.9999999999999999, 'j-non-fiction')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['non-fiction'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_find(tag_id):\n",
    "    tag_name = btt[btt['tag_id']==tag_id]['tag_name'].to_string(index=False).strip()\n",
    "    tag_name = tag_df[int(tag_df.index.values)]\n",
    "    tags = []\n",
    "    for x in range(5):\n",
    "        tags.append(results[tag_name][:5][x][1])\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00-to-read-00',\n",
       " 'exploring-author',\n",
       " 'exploring-classics',\n",
       " 'exploring-quality',\n",
       " '00-in-class']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_find(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--3-'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btt[btt['tag_id']==tag_id]['tag_name'].to_string(index=False).strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
