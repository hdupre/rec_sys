{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify Recommender\n",
    "\n",
    "The video in question:\n",
    "\n",
    "https://www.youtube.com/watch?v=3LBgiFch4_g\n",
    "\n",
    "Chris Johnson, and ML guy at Spotify, discusses his use of Hadoop and Spark at a conference.\n",
    "\n",
    "Spotify is up there with Amazon, Netflix, etc. as the most famous examples of recommender systems applied in a business setting -- they have a huge catalog of albums, artists, songs, and other audio media like podcasts, with millions of users all over the world.\n",
    "\n",
    "### Scale\n",
    "\n",
    "It's all about scale. Chris Johnson discusses other famous music recommenders (Pandora, Songza) and their recommendation techniques, but the failures almost always come down to scale. For example, Pandora has music experts who tag their catalog items with certain attributes like \"vocal grittiness.\" Yet this type of tagging becomes increasingly tedious as a catalog gets larger and larger.\n",
    "\n",
    "Because a company like Spotify is only planning to grow their business and their catalog, techniques that can be applied to most sizes of datasets will have an advantage as it's more efficient to use them over time.\n",
    "\n",
    "### Technologies\n",
    "\n",
    "Johnson discusses that Spotify started out by running Hadoop servers in a backroom at a Spotify office in 2007, but Hadoop suffers from I/O overhead -- it continually reads and writes from the disk in each iteration.\n",
    "\n",
    "Spark does not suffer from this as iterations are loaded into memory. Spotify was also using different iterations of matrix techniques that became progressively faster as techniques were refined. Their final attempt caches ratings rather than shuffling them (a problem with their first attempt) which saves on processing time, but also requires more memory than their previous attempt. The Spark (half gridify) final technique was significantly faster running an ALS algorithm than their Hadoop and Spark (full gridify) methods.\n",
    "\n",
    "It appears that at the time of this video, data processing technologies were moving toward being more memory intensive as a way to save processing time and effort. With the proliferation of cheap and reliable solid state storage in the past ten years, particularly in cloud environemnts, this is an excellent trade-off.\n",
    "\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "The newer Spark technologies they were demonstrating were not in production yet -- was still running Hadoop. Further, they were not able to process the entire set with the techniques discussed in the video. This was posted 6 years ago so undoubtedly Spotify's data team has continued to refine their solution. I did a few searches and it's unclear to me exactly what Spotify is using now.\n",
    "\n",
    "It's likely that that they use a multitude of techniques and are constantly testing and refining so it's impossible to say that one best solution is being used or found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
